remark: /wrk/ci/prod/2022.2/hls_product/continuous/608/2022.2/src/shared/hls/clib/hlsmath/src/c++/expfloat.cpp:22:9: Inlining function 'exp_reduce_::exp(float)' into 'hls::expf(float)'
remark: activation_accelerator.cpp:250:13: Inlining function 'hls::expf(float)' into 'float_safe_softmax(float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:283:13: Inlining function 'hls::expf(float)' into 'float_mask_safe_softmax(float const*, float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:161:29: Inlining function 'hls::expf(float)' into 'float_sigmoid(float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:171:29: Inlining function 'hls::expf(float)' into 'float_silu(float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:341:31: Loop 'VITIS_LOOP_341_2' is marked as complete unroll implied by the pipeline pragma
remark: activation_accelerator.cpp:390:31: Loop 'VITIS_LOOP_390_4' is marked as complete unroll implied by the pipeline pragma
remark: activation_accelerator.cpp:297:0: Unrolling loop 'VITIS_LOOP_341_2' (activation_accelerator.cpp:341:31) in function 'activation_accelerator' completely with a factor of 32
remark: activation_accelerator.cpp:297:0: Unrolling loop 'VITIS_LOOP_390_4' (activation_accelerator.cpp:390:31) in function 'activation_accelerator' completely with a factor of 32
remark: activation_accelerator.cpp:178:0: Inlining function 'hls::sqrtf(float)' into 'float_rms_norm(float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:197:0: Inlining function 'hls::sqrtf(float)' into 'float_layer_norm(float const*, ap_uint<16>*, int)'
remark: activation_accelerator.cpp:297:0: Inlining function 'float_add(float const*, float const*, ap_uint<16>*, int)' into 'activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int)'
remark: activation_accelerator.cpp:297:0: Inlining function 'float_sigmoid(float const*, ap_uint<16>*, int)' into 'activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int)'
remark: activation_accelerator.cpp:297:0: Inlining function 'float_silu(float const*, ap_uint<16>*, int)' into 'activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int)'
remark: activation_accelerator.cpp:297:0: Inlining function 'float_rms_norm(float const*, ap_uint<16>*, int)' into 'activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int)'
remark: activation_accelerator.cpp:297:0: Inlining function 'float_layer_norm(float const*, ap_uint<16>*, int)' into 'activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int)'
remark: activation_accelerator.cpp:317:0: Applying array_partition to '_ZZ22activation_acceleratorP7ap_uintILi512EES1_S1_iiE5tile0': Cyclic partitioning with factor 32 on dimension 1.
remark: activation_accelerator.cpp:317:0: Applying array_partition to '_ZZ22activation_acceleratorP7ap_uintILi512EES1_S1_iiE5tile1': Cyclic partitioning with factor 32 on dimension 1.
remark: activation_accelerator.cpp:317:0: Applying array_partition to '_ZZ22activation_acceleratorP7ap_uintILi512EES1_S1_iiE5tile2': Cyclic partitioning with factor 32 on dimension 1.
remark: activation_accelerator.cpp:332:5: Sequential read of length 1024 has been inferred _XLX_SEP_ OldID=for.inc.load.70,  _XLX_SEP_ in0seq in0 gmem0 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Sequential read of length 1024 has been inferred _XLX_SEP_ OldID=for.inc.load.75,  _XLX_SEP_ in1seq in1 gmem1 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Sequential write of length 1024 has been inferred _XLX_SEP_ OldID=for.inc95.store.175,  _XLX_SEP_ outseq out gmem2 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Could not widen since type i512 size is greater than or equal to the max_widen_bitwidth threshold of 0 _XLX_SEP_ outseq out gmem2 VITIS_LOOP_387_3 activation_accelerator.cpp:387:27 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Could not widen since type i512 size is greater than or equal to the max_widen_bitwidth threshold of 0 _XLX_SEP_ in0seq in0 gmem0 VITIS_LOOP_336_1 activation_accelerator.cpp:336:20 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Could not widen since type i512 size is greater than or equal to the max_widen_bitwidth threshold of 0 _XLX_SEP_ in1seq in1 gmem1 VITIS_LOOP_336_1 activation_accelerator.cpp:336:20 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Multiple burst reads of length 1024 and bit width 512 has been inferred. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings. _XLX_SEP_ seq  gmem0 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Multiple burst reads of length 1024 and bit width 512 in loop 'TILES'(activation_accelerator.cpp:332:5) has been inferred on bundle 'gmem0'. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings.
remark: activation_accelerator.cpp:332:5: Multiple burst reads of length 1024 and bit width 512 has been inferred. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings. _XLX_SEP_ seq1  gmem1 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Multiple burst reads of length 1024 and bit width 512 in loop 'TILES'(activation_accelerator.cpp:332:5) has been inferred on bundle 'gmem1'. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings.
remark: activation_accelerator.cpp:332:5: Multiple burst writes of length 1024 and bit width 512 has been inferred. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings. _XLX_SEP_ seq2  gmem2 TILES activation_accelerator.cpp:332:5 activation_accelerator(ap_uint<512>*, ap_uint<512>*, ap_uint<512>*, int, int) 
remark: activation_accelerator.cpp:332:5: Multiple burst writes of length 1024 and bit width 512 in loop 'TILES'(activation_accelerator.cpp:332:5) has been inferred on bundle 'gmem2'. These burst requests might be further partitioned into multiple requests during RTL generation, based on max_read_burst_length or max_write_burst_length settings.
